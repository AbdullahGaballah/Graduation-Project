{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5511cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f64442",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_coords =501\n",
    "landMarkes =['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landMarkes +=['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182531fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/oprncv/test_vf/test.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landMarkes)    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64effe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in d:\\programs\\anaconda\\lib\\site-packages (0.8.11)\n",
      "Requirement already satisfied: opencv-python in d:\\programs\\anaconda\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: pandas in d:\\programs\\anaconda\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: scikit-learn in d:\\programs\\anaconda\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: matplotlib in d:\\programs\\anaconda\\lib\\site-packages (from mediapipe) (3.3.4)\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\programs\\anaconda\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: opencv-contrib-python in d:\\programs\\anaconda\\lib\\site-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: absl-py in d:\\programs\\anaconda\\lib\\site-packages (from mediapipe) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\programs\\anaconda\\lib\\site-packages (from mediapipe) (1.20.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in d:\\programs\\anaconda\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\programs\\anaconda\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\programs\\anaconda\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programs\\anaconda\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\programs\\anaconda\\lib\\site-packages (from scikit-learn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\programs\\anaconda\\lib\\site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\programs\\anaconda\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\programs\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in d:\\programs\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\programs\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\programs\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (8.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e18df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "719ff637",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e5afee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"unfocus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2848d27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c9977f5d096c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# Recolor Feed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('D:/oprncv/UNFOCUS.mp4')\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "            # Append class name \n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            # Export to CSV\n",
    "            with open('D:/oprncv/test_vf/test.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row) \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e3e2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b2336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/oprncv/test_vf/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d999c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focus</td>\n",
       "      <td>0.501528</td>\n",
       "      <td>0.474411</td>\n",
       "      <td>-0.082952</td>\n",
       "      <td>0.995225</td>\n",
       "      <td>0.496069</td>\n",
       "      <td>0.452557</td>\n",
       "      <td>-0.067683</td>\n",
       "      <td>0.994081</td>\n",
       "      <td>0.495498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507732</td>\n",
       "      <td>0.469205</td>\n",
       "      <td>0.015705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507850</td>\n",
       "      <td>0.467126</td>\n",
       "      <td>0.016655</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focus</td>\n",
       "      <td>0.500289</td>\n",
       "      <td>0.476802</td>\n",
       "      <td>-0.116772</td>\n",
       "      <td>0.994114</td>\n",
       "      <td>0.495189</td>\n",
       "      <td>0.455198</td>\n",
       "      <td>-0.101474</td>\n",
       "      <td>0.992979</td>\n",
       "      <td>0.494785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504121</td>\n",
       "      <td>0.467182</td>\n",
       "      <td>0.014150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504187</td>\n",
       "      <td>0.465272</td>\n",
       "      <td>0.015016</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focus</td>\n",
       "      <td>0.499857</td>\n",
       "      <td>0.478029</td>\n",
       "      <td>-0.119379</td>\n",
       "      <td>0.992658</td>\n",
       "      <td>0.494812</td>\n",
       "      <td>0.456313</td>\n",
       "      <td>-0.104074</td>\n",
       "      <td>0.991732</td>\n",
       "      <td>0.494425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501672</td>\n",
       "      <td>0.466993</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501839</td>\n",
       "      <td>0.465008</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focus</td>\n",
       "      <td>0.499697</td>\n",
       "      <td>0.479158</td>\n",
       "      <td>-0.107869</td>\n",
       "      <td>0.991428</td>\n",
       "      <td>0.494598</td>\n",
       "      <td>0.457348</td>\n",
       "      <td>-0.089532</td>\n",
       "      <td>0.990745</td>\n",
       "      <td>0.494180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506961</td>\n",
       "      <td>0.469361</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507163</td>\n",
       "      <td>0.467385</td>\n",
       "      <td>0.016747</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focus</td>\n",
       "      <td>0.499500</td>\n",
       "      <td>0.480281</td>\n",
       "      <td>-0.066502</td>\n",
       "      <td>0.991234</td>\n",
       "      <td>0.494484</td>\n",
       "      <td>0.458383</td>\n",
       "      <td>-0.047151</td>\n",
       "      <td>0.990624</td>\n",
       "      <td>0.494068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503024</td>\n",
       "      <td>0.467659</td>\n",
       "      <td>0.013195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503178</td>\n",
       "      <td>0.465755</td>\n",
       "      <td>0.013985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class        x1        y1        z1        v1        x2        y2  \\\n",
       "0  focus  0.501528  0.474411 -0.082952  0.995225  0.496069  0.452557   \n",
       "1  focus  0.500289  0.476802 -0.116772  0.994114  0.495189  0.455198   \n",
       "2  focus  0.499857  0.478029 -0.119379  0.992658  0.494812  0.456313   \n",
       "3  focus  0.499697  0.479158 -0.107869  0.991428  0.494598  0.457348   \n",
       "4  focus  0.499500  0.480281 -0.066502  0.991234  0.494484  0.458383   \n",
       "\n",
       "         z2        v2        x3  ...      z499  v499      x500      y500  \\\n",
       "0 -0.067683  0.994081  0.495498  ...  0.002650   0.0  0.507732  0.469205   \n",
       "1 -0.101474  0.992979  0.494785  ...  0.002386   0.0  0.504121  0.467182   \n",
       "2 -0.104074  0.991732  0.494425  ...  0.001432   0.0  0.501672  0.466993   \n",
       "3 -0.089532  0.990745  0.494180  ...  0.003161   0.0  0.506961  0.469361   \n",
       "4 -0.047151  0.990624  0.494068  ...  0.002276   0.0  0.503024  0.467659   \n",
       "\n",
       "       z500  v500      x501      y501      z501  v501  \n",
       "0  0.015705   0.0  0.507850  0.467126  0.016655   0.0  \n",
       "1  0.014150   0.0  0.504187  0.465272  0.015016   0.0  \n",
       "2  0.012090   0.0  0.501839  0.465008  0.012898   0.0  \n",
       "3  0.015826   0.0  0.507163  0.467385  0.016747   0.0  \n",
       "4  0.013195   0.0  0.503178  0.465755  0.013985   0.0  \n",
       "\n",
       "[5 rows x 2005 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4585aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e8f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "611f4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed993527",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f09b79cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programs\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c500573e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6dff24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unfocus', 'unfocus', 'unfocus', 'focus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'focus', 'focus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'focus', 'unfocus', 'focus', 'focus', 'focus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'focus', 'unfocus', 'unfocus', 'focus',\n",
       "       'focus', 'unfocus', 'unfocus', 'focus', 'focus', 'unfocus',\n",
       "       'focus', 'focus', 'unfocus', 'focus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'focus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'focus', 'focus', 'unfocus', 'unfocus', 'focus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'focus', 'unfocus', 'unfocus', 'focus',\n",
       "       'unfocus', 'focus', 'focus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'focus',\n",
       "       'focus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'focus', 'unfocus',\n",
       "       'focus', 'focus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus', 'focus',\n",
       "       'unfocus', 'focus', 'unfocus', 'focus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'focus', 'unfocus', 'focus',\n",
       "       'focus', 'focus', 'unfocus', 'unfocus', 'focus', 'focus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'focus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'focus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'focus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus', 'focus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'focus', 'unfocus',\n",
       "       'focus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'focus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus', 'focus',\n",
       "       'focus', 'focus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rc'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6316fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vEvaluate model\n",
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5486cba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.0\n",
      "rc 1.0\n",
      "rf 0.9958419958419958\n",
      "gb 0.997920997920998\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93405ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unfocus', 'unfocus', 'unfocus', 'focus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'focus', 'focus', 'focus', 'focus', 'focus', 'unfocus', 'unfocus',\n",
       "       'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'focus', 'focus', 'unfocus', 'unfocus', 'focus', 'focus',\n",
       "       'unfocus', 'unfocus', 'focus', 'focus', 'unfocus', 'focus',\n",
       "       'focus', 'unfocus', 'focus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'focus',\n",
       "       'focus', 'unfocus', 'unfocus', 'focus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'focus', 'focus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'focus', 'focus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'focus', 'focus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'focus', 'unfocus', 'focus',\n",
       "       'focus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'focus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'focus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'focus', 'unfocus', 'focus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'focus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'focus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'focus', 'unfocus', 'focus', 'focus', 'focus',\n",
       "       'unfocus', 'unfocus', 'focus', 'focus', 'focus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'focus', 'unfocus',\n",
       "       'unfocus', 'focus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'focus', 'unfocus',\n",
       "       'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'focus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus',\n",
       "       'focus', 'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'focus', 'unfocus', 'focus', 'unfocus', 'focus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'focus', 'focus', 'unfocus', 'unfocus',\n",
       "       'focus', 'unfocus', 'unfocus', 'unfocus', 'focus', 'focus',\n",
       "       'focus', 'unfocus', 'unfocus', 'focus', 'unfocus', 'unfocus',\n",
       "       'unfocus', 'unfocus', 'unfocus', 'unfocus', 'unfocus'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9933facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/oprncv/test_vf/graduation_project.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a768ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test project\n",
    "with open('D:/oprncv/test_vf/graduation_project.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98f5cd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfocus [0.04 0.96]\n",
      "unfocus [0.07 0.93]\n",
      "unfocus [0.1 0.9]\n",
      "unfocus [0.29 0.71]\n",
      "unfocus [0.14 0.86]\n",
      "unfocus [0.01 0.99]\n",
      "unfocus [0.02 0.98]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0.02 0.98]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0.02 0.98]\n",
      "unfocus [0.01 0.99]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n",
      "unfocus [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('D:/oprncv/UNFOCUS.mp4')\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "#             # Append class name \n",
    "#             row.insert(0, class_name)\n",
    "            \n",
    "#             # Export to CSV\n",
    "#             with open('coords.csv', mode='a', newline='') as f:\n",
    "#                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                 csv_writer.writerow(row) \n",
    "\n",
    "            # Make Detections\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            print(body_language_class, body_language_prob)\n",
    "            \n",
    "            # Grab ear coords\n",
    "            coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "            \n",
    "            cv2.rectangle(image, \n",
    "                          (coords[0], coords[1]+5), \n",
    "                          (coords[0]+len(body_language_class)*20, coords[1]-30), \n",
    "                          (245, 117, 16), -1)\n",
    "            cv2.putText(image, body_language_class, coords, \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, body_language_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c5be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
